# 计算机图形学——软光栅渲染器

<center>同济大学软件学院</center>
<center>指导老师：贾金原老师</center>
<center>1754060 张喆<br/>1753188 陈开昕<br/>1652699 林磊</center>
[TOC]

------

## 一. 概述：渲染流水线

**流水线功能**：给定一个虚拟相机、一些三维物体、灯光、着色方程、贴图等资源，最终生成一张二维图片

- **Application（应用程序阶段）**：游戏逻辑、物理等

- **Geometry（几何阶段）**：处理上一个阶段传递来的图元和位置等信息，计算变换位置，最终决定物体在屏幕上的哪个位置。主要是顶点着色器（MVP变换）、裁剪、屏幕映射、裁剪等

  ![image-20200112145239657](img/image-20200112145239657.png)

- **Rasterizer（光栅化阶段）**：将上一阶段变换投影后屏幕空间的顶点（包括顶点包含的各种数据），转化为屏幕上像素的过程。主要是三角形数据的设置、数据差值、像素着色、ALpha测试、深度测试、模板测试、混合等

  ![image-20200112145409483](img/image-20200112145409483.png)

------

## 二. 顶点变换及画线

### 2.1 顶点变换过程

![image-20200112110909019](img/image-20200112110909019.png)

### 2.2 数据结构

#### 2.2.1 矩阵、向量

- **矩阵**

  ```c++
  /* 矩阵 */
  typedef struct
  { 
    float m[4][4]; 
  } matrix_t;  
  ```

- **矩阵运算**

  ```c++
  //c=a+b
  void matrix_add(matrix_t *c,const matrix_t *a,const matrix_t *b);
  //c=a-b
  void matrix_sub(matrix_t *c,const matrix_t *a,const matrix_t *b);
  //c=a*b
  void matrix_mul(matrix_t *c,const matrix_t *a,const matrix_t *b);
  //c=a*i
  void matrix_scale(matrix_t *c,const matrix_t *a,float i);
  //y=x*m;向量和矩阵相乘
  void matrix_apply(vector_t *y,const vector_t *x,const matrix_t *m); 
  //重置为单位矩阵
  void matrix_set_identity(matrix_t *m); 
  //重置为零矩阵 
  void matrix_set_zero(matrix_t *m);
  //平移变换的平移矩阵 
  void matrix_set_translate(matrix_t *m,float x,float y,float z); 
  //缩放变换的缩放矩阵
  void matrix_set_scale(matrix_t *m,float x,float y,float z); 
  //旋转变换的旋转矩阵
  void matrix_set_rotate(matrix_t *m,float x,float y,float z,float theta); 
  //摄像头设置
  void matrix_set_lookat(matrix_t *m,const vector_t *eye,const vector_t *at,const vector_t *up);
  //透视投影矩阵设置
  void matrix_set_perspective(matrix_t *m,float fovy,float aspect,float zn,float zf);
  ```

- **向量**

  ```c++
  /*向量*/
  typedef struct
  {
    float x;
    float y;
    float z;
    float w;
  } vector_t;
  ```

- **向量运算**

  ```c++
  //如果x超出了边界，就选边界；如果x没有超出边界，就选x；在判断颜色值的时候用到
  int CMID(int x,int min,int max);
  //z=x+y
  void vector_add(vector_t *z,const vector_t *x,const vector_t *y);
  //z=x-y
  void vector_sub(vector_t *z,const vector_t *x,const vector_t *y);
  //数量积
  float vector_dotproduct(const vector_t *x,const vector_t *y);
  //向量积 
  void vector_crossproduct(vector_t *z,const vector_t *x,const vector_t *y);
  //计算插值：t∈[0,1] 
  float interp(float x1,float y1,float t);
  //矢量插值：t∈[0,1]
  void vector_interp(vector_t *z,const vector_t *x,const vector_t *y,float t); 
  //矢量归一化 
  void vector_normalize(vector_t *v); 
  ```



#### 2.3 坐标变换

```c++
/* 坐标变换 */
typedef struct
{
  matrix_t world;				//世界坐标系变换 
  matrix_t view;				//照相机坐标变换 
  matrix_t projection;	//投影变换 
  matrix_t transform;		//transfrom=world*view*projection 
  float w;							//宽 
  float h;							//高 
} transform_t;
```

- **坐标变换相关方法**

  ```c++
   //矩阵更新，计算：transfrom=world*view*projection 
   void transform_update(transform_t *ts);
   //初始化，设置屏幕宽高和变换矩阵 
   void transform_init(transform_t *ts, int width, int height); 
   //将点坐标进行坐标变换
   void transform_apply(const transform_t *ts, vector_t *y, const vector_t *x); 
   //检查齐次坐标同CVV的边界用于视锥体的裁剪
   int transform_check_cvv(const vector_t *v); 
   //归一化，得到屏幕坐标 
   void transform_homogenize(const transform_t *ts, vector_t *y, const vector_t *x);
  ```



#### 2.3 几何计算

- **RGB颜色**

  ```c++
  /* RGB颜色 */
  typedef struct
  {
    float r;
    float g;
    float b;
  } color_t;
  ```

- **纹理坐标**

  ```c++
  /* 纹理坐标 */
  typedef struct
  {
    float u;
    float v;
  } texcoord_t;
  ```

- **顶点**

  ```c++
  /* 顶点 */
  typedef struct
  {
    point_t pos;
    texcoord_t tc;
    color_t color;
    float rhw;			//rhw=1/w，用来做深度测试用的；经过projection乘法后，w与z是线性关系，所以用z做深度测试，可以用w缓存来代替，因为除法代价太大，所以事先保存成1/w  
  } vertex_t;
  ```

- **边**

  ```c++
  /* 边 */
  typedef struct
  {
    vertex_t v;			//保存Y=y与left、right的交点 
    vertex_t v1;
    vertex_t v2;
  } edge_t;
  ```

- **梯形**

  ```c++
  /* 梯形 */
  typedef struct
  {
    float top;			//方便水平扫描线识别扫描的垂直范围 
    float bottom;
    edge_t left;		//左边的边 
    edge_t right;		//右边的边 
  } trapezoid_t;
  ```

- **扫描线**

  ```c++
  /* 扫描线 */
  typedef struct
  {
    vertex_t v;			//v中存放的是扫描线的浮点型，也即原来left与Y=y的交点，存放当前扫描线的点 
    vertex_t step;	//步长 
    int x;					//x,y中存放的是扫描线起点的整型，因为像素是整型的 
    int y;
    int w;					//扫描线的宽 
  } scanline_t;
  ```

- **几何变化相关方法**

  ```c++
   //除pos坐标外，全部除rhw，颜色、纹理渐变，若点不是在同一深度，就需要把z方向上的渐变也考虑进去，所以要同除w
   void vertex_rhw_init(vertex_t *v); 
   //顶点插值
   void vertex_interp(vertex_t *y,const vertex_t *x1,const vertex_t *x2,float t);
   //步长计算有用到 
   void vertex_division(vertex_t *y,const vertex_t *x1,const vertex_t *x2,float w);
   //顶点加法 
   void vertex_add(vertex_t *y,const vertex_t *x); 
   //按照Y坐标计算出左右两边纵坐标等于 y 的顶点 
   void trapezoid_edge_interp(trapezoid_t *trap,float y); 
   //根据左右两边的端点，初始化计算扫描线的起点和步长
   void trapezoid_init_scan_line(const trapezoid_t *trap,scanline_t *scanline,int y); 
   //根据三角形生成0~2个梯形，并且返回合法梯形的数量（我的注释：将三角形分割成可以扫描的水平三角形）
   int trapezoid_init_triangle(trapezoid_t *trap,const vertex_t *p1,const vertex_t *p2,const vertex_t *p3);
  ```

  

### 2.4 坐标变换

#### 2.4.1 基础知识

![坐标变换](/Users/sTern/Downloads/EE_Study/3.0/计算机图形学/归档/计算机图形学——软光栅渲染器.assets/坐标变换.png)

3D物体从三维空间映射到二维屏幕，需要经历一系列坐标系变换：

1. **model**：局部坐标系（物体原本的坐标系），是相对的坐标系，主要进行模型空间的绘制
2. **world**：世界坐标系，物体放在世界里的坐标。系统的绝对坐标系，在没有建立用户坐标系之前所有点的坐标都是以该坐标系的原点来确定的
3. **camera**：相机坐标系，相机也是世界里的一个物体，相机坐标就是以相机位置为坐标原点，相机的朝向为Z轴方向的坐标系。因为我们在电脑里看到的物体其实都是“相机”帮助我们看的，“相机”就是我们的眼睛，所以要以相机为标准进行坐标转换
4. **perspective**：透视坐标系，三维坐标向二维平面进行映射。(x, y)的范围 在[-1, 1]，z 的范围在[0, 1]
5. **screen**：屏幕坐标系，原点在屏幕的左上角，x 轴朝右，y 轴朝下。x 的范 围在[0, xres-1]，y 的范围在[0, yres-1]

**注意**

- 物体的位移、缩放、旋转会改变它的world坐标，不会改变model坐标
- 在model、world、camera坐标下，X、Y、Z的范围都是无穷大，但是坐标系的基准不一样
- 在实际的渲染引擎运行中，Xsp和Xpc基本不会改变，因为屏幕分辨率很少会改变
- Xcw会在相机移动和旋转时改变
- Xwm会在物体平邑、旋转和旋转时改变

#### 2.4.2 model到world的转换

从模型本身的相对坐标变换到世界坐标，主要是平移、旋转和缩放

本项目中
$$
world = \begin{bmatrix}1 & 0 & 0 & 0 \\ 0& 1 & 0 & 0 \\0 & 0 & 1 & 0 \\0 & 0 & 0 & 1\\\end {bmatrix}
$$

- **平移**

  - 每次按下键盘方向上下键改变pos

    ```c++
    camera_at_zero(&device, pos, 0, 0)
    ```

  - 改变camera中eye位置，即改变坐标变换中view矩阵

- **旋转**

  - 每次按下键盘方向左右键改变alpha

    ```c++
    matrix_set_rotate(&m, -1, -0.5, 1, alpha)
    ```

  - 例. 旋转改变world坐标系，在该项目中，设绕(-1, 0.5, 1)旋转，先旋转两次使旋转轴与坐标轴重合，再绕坐标轴旋转alpha角度，再呈上旋转你矩阵，将旋转轴转动回来

    按下图方式进行world矩阵的求解

    ![image-20200112154946332](img/image-20200112154946332.png)

#### 2.4.3 world到camera的转换

1. 设相机的中心点在世界中的位置时$C(C_x,C_y, C_z)$，相机正在看的点点位置是$I(I_x, I_y,I_z)$
2. 则，相机的Z轴就是它看的方向向量，即$CI$向量，即$I-C = (I_x-C_x, I_y-C_y, I_z-C_z)$，将其归一化得到Z轴单位向量
3. 取世界坐标系中的$up$向量$(0,1,0)$, $up^{'} = up-(up·Z)Z$
4. 将$up^{'}$归一化得到Y，$Y\times Z = X$
5. 将$up \times Z$，得到向量$X_1$，将$X_1$归一化，得到X轴的单位向量
6. 再通过Z轴的单位向量与X轴的单位向量叉乘，即$Z \times X$，就得到了Y轴的单位向量

![image-20200112160857457](img/image-20200112160857457.png)

**构造坐标系转换的变换矩阵**：

1. 世界坐标系中，相机原点为$(C_x,c_y,C_z)$，在相机坐标系中为$(0,0,0)$，因此$(0,0,0)=Xuw*(C_x,C_y,C_z)$

2. 世界坐标系中，相机的三个轴为$X+C(X_x+C_x,X_y+C_y,X_z+C_z), Y+C(Y_x+C_x,Y_y+C_y,Y_z+C_z), Z+C(Z_x+C_x,Z_y+C_y,Z_z+C_z)$，但在相机坐标系下为$(1,0,0),(0,1,0),(0,0,1)$

   因此
   $$
   (1,0,0)= X+C(X_x+C_x,X_y+C_y,X_z+C_z)\\
   (0,1,0)=  Y+C(Y_x+C_x,Y_y+C_y,Y_z+C_z)\\
   (0,0,1)= Z+C(Z_x+C_x,Z_y+C_y,Z_z+C_z)
   $$

3. 综上可求出$X_{iw}$，表示先把坐标系移动到相机的原点处，然后再旋转来调整到相机的X，Y，Z轴
   $$
   X_{iw} = \begin{pmatrix} X_x & X_y & X_z & -X·C \\ Y_x & Y_y & Y_z & -Y·C \\Z_x & Z_y & Z_z & -Z·C \\ 0 & 0 & 0 & 1\end{pmatrix}
   $$

#### 2.4.4 camera到perspective的转换

- **视锥体**：视椎体是能看到的区域，从眼睛或者摄像机的焦距一直到能看到的最远距离其中的空间。由于越远的东西看上去越小，可以看到的范围也就越大。这样，从焦距到可以看到的最远距离的可见区域增大，使得整个可见区域变成一个椎体，这就是视椎体

  原点到焦距的距离称为近平面距离，用字母 n 表示;原点到最远可见距离 称为远平面距离，用字母 f 表示。这两个平面的距离就是视椎体的“高(z 轴)” 用字母 d 表示。视角代表一个椎体的顶点角度，这个角度越宽视野就越开阔。但是电脑屏幕是矩形的，这个椎体不是圆锥，而是一个四棱锥，因此存在垂直视角和水平视角的问题。

- 投射矩阵的左右就是把一个视锥体变换到一个规范化设备坐标上

- 规范化设备坐标是一个立方体，在 WebGL 中，它的坐标是从(-1,-1,-1)到 (1,1,1)。在这个区域中的东西就被正交投影到屏幕上。因此需要构造一个投射矩 阵把视椎体的东西变换到规范化设备坐标上。因此只要把视椎体变成立方体就可以了。由于上面规定了它是个正四棱锥，所以x方向和y方向的处理是完全一样 的

- 把视锥的x和y坐标都变换到规范设备区域坐标的范围内，这样就可以得到一个细长的长方体

![image-20200112192529941](img/image-20200112192529941.png)

#### 2.4.5 perspective到screen的转换

- **归一化设备坐标**：透视除法，将所有项都除以w，将最后一项变为1
- **将归一化的设备坐标转化为屏幕坐标**：定义屏幕分辨率为$xs × rs$，要将透视坐标系里的点映射过来。屏幕坐标系的原点是左上角，而 perspective 里的原点(0，0)在屏幕中应该位于屏幕中央， 即$(\frac{xs}{2}, \frac{ys}{2})$。那么 perspective 里的原点(0，0)会映射为$(\frac{xs}{2}, \frac{ys}{2})$， 即位移一个(xs/2, ys/2，0)。屏幕坐标系中 x 的范围是[0, xs)，y 的范围是[0, ys)。而 perspective 坐标系中 x 和 y 的范围是[-1,1]，所以这个映射还要满足-1 映射到0，1映射到xs或ys。

![image-20200112193342603](img/image-20200112193342603.png)

- 之后，将顶点坐标乘以transform吼再转换为屏幕坐标
  $$
  Transform = world * view * projection
  $$

### 2.5 以线框形式绘制立方体

1. 立方体每四个点构成一个平面，因此绘制立方体需要绘制六个四边形

2. 四边形中每三个点构成一个三角形，因此画一个四边形需要画两个原始三角形

3. 将每个顶点坐标乘以transform矩阵转换到CVV中，判断该点是否在CVV范围内，若三个点中有一个点不在，则不需要画这个三角形

4. 将符合要求的顶点坐标从CVV坐标再归一化到屏幕坐标（所有坐标除以w，将齐次坐标的最后一项变为1，并转化为屏幕坐标）

5. 一个三角形有三条线段构成，因此已知亮点，绘制出一条线段

   已知两点画线段

   - 两点为同一点时，画出该点即可
   - 两点横坐标或纵坐标不同时想等时（即该线段为水平或垂直时），循环画出每个点以构成一条线段
   - 其他情况，采用中点画线算法画直线，需要考虑x，y方向哪个方向变化快（斜率和1点关系）

   <img src="img/image-20200112194846169.png" alt="image-20200112194846169" style="zoom:50%;" />

   <img src="img/image-20200112194904964.png" alt="image-20200112194904964" style="zoom:50%;" />

   ```c++
   /* 初始 */
   a = y0 - y1;
   b = x1 - x0;
   d0 = 2*a+b;
   d1 = 2*a;
   d2 = 2*(a+b);
   
   /* 循环 */
   for(x=x0; x<x1; ++x){
     drawPixel(x, y, color);
     
     if d < 0{
       y += 1;
       d += d2;
     }else{
       d += d1;
     }
   }
   ```

   



------

## 三. 光栅化

### 3.1 数据结构

#### 3.1.1 渲染设备

```c++
/* 渲染设备 */
typedef struct
{
  transform_t transform;			//坐标变换器 
  int width;									//窗口宽度 
  int height;									//窗口高度  
  IUINT32 **framebuffer;			//像素缓存：framebuffer[y]代表第y行，存储的是颜色(32位)
  float **zbuffer;						//深度缓存
  IUINT32 **texture;					//纹理 
  int tex_width;							//纹理宽度 
  int tex_height;							//纹理高度 
  float max_u;								//纹理最大宽度：tex_width - 1 
  float max_v;								//纹理最大高度：纹理坐标：v*max_v，其中v∈[0,1] 
  int render_state;						//渲染状态 
  IUINT32 background;					//背景颜色 
  IUINT32 foreground;					//线框颜色 
  light_t light;							//光照
} device_t;
```

- **渲染设备相关方法**

  ```c++
  //设备初始化，fb为外部帧缓存，非NULL将引用外部缓存帧缓存（每行对齐4字节） 
  void device_init(device_t *device,int width,int height,void *fb);
  //删除设备
  void device_destroy(device_t *device);
  //设置当前纹理 
  void device_set_texture(device_t *device,void *bits,long pitch,int w,int h); 
  //清空framebuffer和zbuffer
  void device_clear(device_t *device,int mode);
  //画点 
  void device_pixel(device_t *device,int x,int y,IUINT32 color);
  //画线段 
  void device_draw_line(device_t *device,int x1,int y1,int x2,int y2,IUINT32 c);
  //根据坐标读取纹理 
  IUINT32 device_texture_read(const device_t *device,float u,float v);
  ```

  

#### 3.1.2 状态变量

```c++
const int RENDER_STATE_WIREFRAME=1;										//渲染线框
const int RENDER_STATE_TEXTURE=2;											//渲染纹理 
const int RENDER_STATE_COLOR=4; 											//渲染颜色
const int RENDER_STATE_LIGHT_GLOBAL_AMBIENT=8;				//全局环境光
const int RENDER_STATE_LIGHT_DIFFUSE_REFLECTION=16;		//漫反射光
```



###3.2 基本要求

将一组三位顶点光栅化为 2d。

光栅化其实就是将几何数据经过一系列变换后最终转换为像素，从而呈现在显示设备上的过程。它的本质是坐标变换、几何离散化。



### 3.3 空间基本元素——三角形的光栅化

三个点就能确定一个三角形，再加一个参数，尝试绘制一个三角形并给内部填充颜色。最简单的填充就是扫描线填充，换句话说我们按照屏幕的y轴方向，从上向下，每一行进行绘制，直到把三角形全部填充上为止。

- 三角形的分类：

  首先要把三角形分一下类：平底，平顶和能够拆分成前两种三角形的一般三角形。

  ![img](img/2-1.png)

  已知y的方向，那么就需要代入三角形边的直线方程求得x的坐标，然后在两个点之间画线。如果三角形是平顶的或者是平底的，那么我们只需要考虑两条边即可；如果是一般的三角形，就把三角形划分成一个平顶三角形和一个平底三角形，以上图为例，三角形GHI，以H的y值带入GI直线方程求得J的x坐标，生成GHJ和HJI两个三角形，这两个三角形就可以按照平顶和平底的方式进行光栅化了。

- 一边水平的三角形的光栅化

  以平底三角形ABC为例，假设A（x0，y0），B（x1，y1），C（x2，y2），AB直线上随机一点（x，y）,那么直线方程如下：

  （y - y1） / （x - x1） = （y0 - y1） / （x0 - x1）

  我们已知y（从y0到y1循环），则x值为： x = （y - y0） * (x0 - x1) /  (y0 - y1) + x1。AC边类似得到x值，那么循环中我们就可以根据y值得到每条扫描线左右的x值。填充左右x之间的像素即可。



### 3.4 透视投影变换

#### 3.4.1 CVV裁剪

经过了透视变换，坐标被变换到CVV空间，此时仍然是齐次坐标，我们正常应该是判断在裁剪的立方体内，不过齐次坐标直接比较xyz值和w的值即可，其中**z需要比较0和w**。这个是非常重要的，因为默认为了方便是把投影平面放到了眼睛前面，但是真的有在投影平面后面的东西，如果不剔除z<0的内容，就会导致这一部分按照不对的透视公式进行计算导致结果错误。而且更重要的一点在于，相机空间z = 0的时候（也就是齐次空间的w = 0）的这种情况，在我们透视除法的时候会有除0的问题。所以要把这个剔除掉。

比如一个齐次空间的顶点，我们可以按照上述方式判断其是否在CVV内：

```c++
int transform_check_cvv (const vector_t *v) {
	float w = v->w;
	int check = 0;
	if (v->z < 0.0f) check |= 1;
	if (v->z >  w) check |= 2;
	if (v->x < -w) check |= 4;
	if (v->x >  w) check |= 8;
	if (v->y < -w) check |= 16;
	if (v->y >  w) check |= 32;
	return check;
}
```



#### 3.4.2 透视除法与屏幕坐标映射

经过了之前的透视投影变换和CVV裁剪，现在顶点坐标都在齐次裁剪空间，紧接着就是真正地进行透视除法，经过了这一步才真正算是完成了透视投影变换。

因为计算在透视投影矩阵的构建中我们都推导过了，w坐标不会是默认的1。因为我们把Z值存了进去。此时我们将三个分量都除以Z，就得到了透视变换后的NDC坐标了。所谓NDC，全称为Normalized Device Coordinates，也就是标准设备空间，引入这样一个空间的原因主要在于使用不同的设备，分辨率可能都不一样，实际在写shader的时候，没办法根据分辨率进行调整，而通过这样一个空间，把x，y映射到（-1,1）区间，z映射到（0,1）区间（OpenGL是（-1,1）），在下一步屏幕坐标映射时再根据屏幕分辨率生成像素真正应该在的位置，这样可以省掉很多设备适配的问题。

创建窗口的时候，会给一个窗口的宽度和高度，既然我们得到了NDC空间的坐标值了，并且知道了屏幕的长和宽（分辨率），那么，就可以将这个坐标映射到屏幕上去：NDC是（-1,1）区间（暂时只考虑X，Y），我们要把它映射到屏幕的（0，width）和（0，height）区间即可。

先看X方向：首先，我们从（-1,1）区间映射到（0,1）区间，再映射到屏幕上，也就是（ x / w + 1）* 0.5 * deviceWidth。Y方向，屏幕实际的坐标是左上角为（0,0）点，与我们的NDC是反过来的，所以映射到（0,1）区间后，还需要反向一下，改为（1 - y / w）* deviceHeight。之后再将 z 除以 w ，将w置回1。

代码如下，进行了透视除法&屏幕空间映射：

```c++
float rhw = 1.0f / x->w;
y->x = (x->x * rhw + 1.0f) * ts->w * 0.5f;
y->y = (1.0f - x->y * rhw) * ts->h * 0.5f;
y->z = x->z * rhw;
y->w = 1.0f;
```



### 3.5 光栅化数据插值

对于一维的插值代码，也就是的Lerp函数：

`float LerpFloat(float v1, float v2, float t){ return v1 + (v2 - v1) * t;}`

原理其实非常简单，我们给一个（0，1）的插值控制函数，就可以完成从v1，v2之间的插值了，当t=0时，为v1，当t=1时为v2。

在 2D 平面上，一条直线可以表示为斜截式：y = Ax + B。这个形式也表示变量 x和 y 是线性关系。也就是说，只要参数 A 和 B 定下来，则 x 和 y 就有了一个固定的对应关系，有一个 x，在直线上就有唯一一个 y 和它对应。更具体地说，比如 x 的范围是[X0, X1]，则对应的 y 范围就是[Y0, Y1]。线性关系的两个变量可以进行线性插值，线性插值公式和直线公式其实是一致的。也就是说，如果两个变量是线性关系，就可以对它们进行线性插值，从而从一个变量 x 得到另一个变量 y。

在三角形设置好之后，三个顶点的数据是一定的，接下来要从上到下绘制扫描线，我们每次要绘制扫描线的时候，首先要获得扫描线两侧端点的数据值，扫描线的两侧端点的值在我们求解方程的时候可以得到，也就能求出该点在端点所在的边所处的值，此处是从上到下，那么我们就用y作为插值系数，以即每一点的 t = （y - y0）/ （y2 - y0），然后我们就可以用这个系数去在顶点和底点两个点之间插值得到当前线上扫描线起始点和结束点的颜色值。扫描线本身也是同理，已知左右两点的颜色值，每次前进一个像素，都可以求出当前 t = （x - x0） / （x1 - x0）作为插值系数。所以当给上面的三角形增加一个顶点色，通过插值就可以得到颜色渐变的效果。



------

## 四. 纹理

### 4.1 基本：仿射纹理映射

假设投影平面上的 x、y 和纹理坐标 s、t 是线性关系。

目前只有顶点数据，也就是展uv得到的坐标值s、t，存在顶点中。像素上全靠插值，那么要想贴上一张图，应该有的其实是这一个像素点应该采样的纹理坐标也就是uv值。补全插值的计算和顶点上的uv数据，获取信息时读入一张bmp贴图，构建一个二维数组，然后把这个贴图的每个像素逐步拷入数组。采样时，计算出uv值，把uv的（0,1）区间映射到像素数组的大小，就可以用这个index去纹理数组中采样该点的颜色了。

用三角形举例子，视口中的一个平底三角形有三个顶点P0，P1和P2，分别有相应的x，y和z三个坐标，其中x和y是从NDC通过视口变换转换过来的，而z可能是NDC的数据，也可能是从NDC变成视口自己的z范围中。s和t就是每个顶点的纹理坐标值，它是一直从模型坐标带过来或者是通过API自动生成的，始终没有进行过处理。

![三角形的例子](img/2-3.gif)

仿射纹理映射过程有两重循环。在第一层循环的时候，我们通过左右两边的直线方程以及当前的y，计算出左边线段的x和右边线段的x，左边线段的s、t和右边线段的s、t。然后计算出s和t针对于的x变化量。第二层循环就是实际绘制扫描线，绘制的同时根据纹理坐标变化量更新s和t，然后把s和t所指向的纹理值赋给当前的插值像素点。



### 4.2 实际：1/Z与透视矫正纹理映射

实际上投影平面上的 x、y 和纹理坐标 s、t 并不是线性关系。

![两个三角形](img/2-2.png)

左右两侧的两个三角形唯一的区别就在于左侧CFE平面平行于近裁剪面，而右侧把CFE整个一条线拉歪，使C接近近裁剪面。二者在最终投影在近裁剪面的位置完全相同，但是实际上在三维空间位置是相差甚远的。

通过以下的证明可以得到，在投影空间的值与1/z成正比。

![证明过程](img/2-5.png)

以上图举例，结论：一般若 $EF=kFG$ ，则$(\frac{1}{h_1}-\frac{1}{h_2}) = k(\frac{1}{h_2}-\frac{1}{h_3})$。

证明：作平行线EE'，GG'，设平行线EFG和虚线之间的距离为 h ，等式两边乘上 h 。

$$\begin{aligned}
&左 =\frac{\mathbf{h}}{\mathbf{h}_{1}}-\frac{\mathbf{h}}{\mathbf{h}_{2}}=\frac{\mathbf{D} \mathbf{E}}{\mathbf{D} \mathbf{A}}-\frac{\mathbf{D} \mathbf{F}}{\mathbf{D} \mathbf{B}}=\frac{\mathbf{D} \mathbf{E}^{\prime}-\mathbf{D} \mathbf{F}}{\mathbf{D} \mathbf{B}}=\frac{\mathbf{E}^{\prime} \mathbf{F}}{\mathbf{D} \mathbf{B}}\\
&右 =\mathbf{k}\left(\frac{\mathbf{h}}{\mathbf{h}_{2}}-\frac{\mathbf{h}}{\mathbf{h}_{3}}\right)=\mathbf{k}\left(\frac{\mathbf{D F}}{\mathbf{D B}}-\frac{\mathbf{D G}}{\mathbf{D C}}\right)=\mathbf{k} \frac{\mathbf{D F}-\mathbf{D G}^{\prime}}{\mathbf{D B}}=\frac{\mathbf{k} \mathbf{F G}^{\prime}}{\mathbf{D B}}
\end{aligned}$$

$又 \because \triangle E F^{\prime} F \sim \triangle G G^{\prime} F$

$\therefore \frac{\mathbf{E}^{\prime} \mathbf{F}}{\mathbf{G G}^{\prime}}=\frac{\mathbf{E F}}{\mathbf{F G}}=\mathbf{k}$

$\therefore 左 = 右$



顶点中的数据，顶点颜色，顶点上纹理坐标s、t等内容，都是在模型空间下制作的，这些值实际上应该在模型空间下进行插值计算，但是投影是一个损失维度的变换，单纯地用最终二维屏幕上的位置距离去插值，如果Z全都一致，那没有影响，在投影平面均匀变换的值，对应相机空间（推回模型空间也一样）也是均匀变换的。但是像右侧的倾斜的平面，在投影平面两段相同距离对应相机空间的距离就不同了。

在推导投影矩阵时，投影点的坐标（Nx/z，Ny/z，N）有如下推导。

![示例图](img/2-4.png)

上图是一个视锥体的截面图（只看x，z方向），P为空间中一点（x，y，z），那么它在近裁剪面处的投影坐标假设为P’(x'，y'，z’)，理论上来说，呈像的面应该在眼睛后方才更符合真正的小孔呈像原理，但是那样会增加复杂度，没必要额外引入一个负号。只考虑三角形相似，即三角形EAP’相似于三角形EGP，我们可以得到两个等式：

$$
\left\{\begin{array}{l}
{x^{\prime}=-N \frac{x}{z} \Rightarrow x=-\frac{x^{\prime} z}{N}} \\
{y^{\prime}=-N \frac{y}{z} \Rightarrow y=-\frac{y^{\prime} z}{N}}
\end{array}\right.
$$
由于投影面就是近裁剪面，那么近裁剪面是我们可以定义的，我们设其为N，远裁剪面为F，那么实际上最终的投影坐标就是（Nx/z，Ny/z，N）。

换句话说，投影后的x’本身就是与1/z呈线性关系的，因此我们可以在投影面上通过 x’和 y’对 1/z 进行线性插值。再通过相似三角形得出的 x 和 x' 的转换关系计算出原始的 x 和 y，然后在 3D 空间中通过 x 和 y 计算出 s 和 t（x、y 和s、t 都是在 3D 空间中的三角形上定义的，是线性关系）。这样就找到了投影面上一个点所对应的纹理坐标的正确值了。

同时我们可知，空间中x、y、s、t是线性的：

$$\left\{\begin{array}{l}
{x=A s+B} \\
{x=A t+B} \\
{y=A s+B} \\
{y=A t+B}
\end{array}\right.$$

代入上面的等式求x'、y'可知：
$$
\left\{\begin{array}{l}
{\frac{s}{z}=A x^{\prime}+B} \\
{\frac{t}{z}=A x^{\prime}+B} \\
{\frac{s}{z}=A y^{\prime}+B} \\
{\frac{t}{z}=A y^{\prime}+B}
\end{array}\right.
$$
如果将s、t都除以z，如上能够发现 s/z、t/z 和 x’、y’也是线性关系。且已知 1/z 和 x’、y’是线性关系。所以可以对 1/z 关于 x’、y’插值得到 1/z’，然后对 s/z、t/z 关于 x’、 y’进行插值得到 s’/z’、t’/z’，然后用 s’/z’和 t’/z’分别除以 1/z’，就得到了插值 s’和 t’。以此达到简化计算的目的。



### 4.3 补充：ZBuffer

ZBuffer的思想比较简单，在逐像素增加一个缓存，每次绘制的时候，把当前深度也存储进这个buffer，下次再绘制该像素的时候，先判断一下当前像素的z值，如果比该值小或相等的话，说明离得更近。这种情况下就可以更新当前像素点的颜色值，并且可以选择更新深度缓存。

三角形光栅化中基本的扫描线填充的算法也加入ZBuffer的考虑变成如下：

```
从扫描线的起点开始向右绘制直到结束：
begin：
	if 当前位置的深度比存储了的更近
		更新深度缓存 zbuffer
		if 颜色模式
			framebuffer 添加颜色信息 
		if 纹理模式
			framebuffer 添加纹理信息
end;
```







------

## 五. 光照

### 5.1 数据结构

```c++
/* 光照 */
typedef struct  
{
  color_t light;//光照颜色
  point_t pos;//光照位置
} light_t;
```

- **光照相关方法**

  ```c++
   //全局环境光
   void global_ambient_light(device_t *device,light_t *light);
   //设置光照颜色
   void set_light_color(light_t *light,float r,float g,float b);
   //设置光照位置
   void set_light_pos(light_t *light,int x,int y,int z);
   //光照
   void open_light(device_t *device,light_t *light);
   //加载图片
   void loadbmp(const char *szfilename,IUINT32 t[256][256]);
  ```

###5.2 基本介绍

物体的颜色是它反射的光的颜色。光是白色的，但它的白色是由许许多多不同颜色不同频率的光混在一起呈现的。实现光照，就要去模拟物体的反射光，让物体有明暗关系，有亮面有暗面。

###5.3 环境光

环境光颜色计算公式为：lj = la Ka。la是环境光的颜色，Ka 是物体的环境光系数，一般而言 Ka = Kd = 物体本身的颜色，只有高光的 Ks不是物体本身的颜色，而是偏白色。

###5.4 漫反射

当光照射到物体上面，物体会反射自身的颜色，这是最基本的反射，会根据光照方向产生明暗关系。

如下图，取单独一个切面来进行分析：

![](img/入射与法线.jpg)

N是物体的法线，L 是入射光的方向向量，le 是入射光的颜色，则反射光的颜色强度 lj 满足：lj = le Kd cos(θ) 或者 lj = le Kd (L·N)。其中，Kd 是物体本身的颜色。光照方向向量和法线都是标准化之后的。颜色向量的 RGB范围都是 0~1。

物体反射的颜色，是物体本来的颜色和照射物体的光的颜色的混合。物体本身颜色和光的颜色的混合比例通过θ来确定，当θ为 0，即光正对着使劲照物体，那物体就是很亮的光的颜色。当光正好和物体平行擦着过去，那物体就没颜色了，黑色的。光对物体越正，物体就越亮，否则越暗。

###5.5 高光

光滑的物体会有一小部分特别亮的地方，趋近于镜面反射。

![](img/高光.jpg)

如上图所示，中间圆形白色就是高光。同一个小球，左上偏亮右下偏暗，这样的明暗关系是漫反射。高光颜色强度公式为：

![](img/高光公式.jpg)

高光和视角有关系，V 是视角向量。Ks 是物体镜面反射的颜色，一般是白色。R 是反射光的方向向量，即 L入射光关于法线 N的对称向量。spec是反射强度。

镜面反射（高光）的颜色是入射光的颜色和镜面反射光的颜色的叠加。镜面反射光的强度取决于视角以及 spec。当 V 和 R平行时，即反射的光直射眼睛，会特别亮。到 V 和 R 垂直时，光照全都照不进眼睛，就没有镜面反射（高光）。

###5.6 小结

计算光照的时候是在相机坐标系空间下。所以 E（视角向量）永远都是（0，0，-1），（我们往正前方看其实是往 Z=1的地方看，它的反向量就是 -1）。因为光照计算涉及方向向量 L, E, N, R，而从 image 变换到 perspective 空间会扭曲图形损失信息，所以我们需要在仿射空间（即 model， world， image 3个 space）进行变换。

在 image 空间下，法线等方向向量都要变换到 image space，但是，法线的变换是只有旋转，没有位移和缩放的。因为法线如果位移，即在法线向量上加一个位移向量，两个向量如果不平行，那么和向量的方向会和原法线不一致。

当 E 和 L 不在一边的时候，即我们在看物体正面，光从物体背面照过来，我们是什么都看不见的，是黑色，这种情况直接跳过不再计算。当 E 和 L 在同一边，但法线 N在另一边的时候，算出来是负的，这时要把法线取反再进行计算。

计算结果要保证最后的颜色 RGB在 0~1范围内。

------

## 六. 实验结果

### 6.1 纹理模式

![](img/show_0.png)

### 6.2 光影效果

![](img/show_1.png)

### 6.3 裁剪改进

![](img/show_3.png)



------

## 七. 代码实现

整个项目分为一个main函数和多个头文件，main函数包含了主要的事件逻辑，便于简单直观的理解。

- bitmap.h：位图图像信息相关获取
- coordinate.h：坐标变换相关函数
- device.h：内存分配、渲染设备相关函数
- geometry.h：几何计算相关函数
- math.h：数学库函数
- render.h：渲染相关函数
- window.h：窗口设置相关函数

详细代码请见源码。



------

## 八. 参考资料

1. 深入探索透视纹理映射

   https://blog.csdn.net/u012419410/article/details/41989501

2. mini3D

   http://www.skywind.me/blog/archives/1498

3. 视图矩阵(View Matrix)的推导

   https://www.web-tinker.com/article/20177.html

4. 投射矩阵(Projection Martrix)的推导

   https://www.web-tinker.com/article/20157.html

5. OpenGL 学习脚印:OpenGL 坐标变换

   http://www.360doc.com/content/14/1028/10/19175681_420522107.shtml